---
title: "Noval statistical Methods for Composite Endpoints"
author: 
  - "Tuo Wang"
  - "Advised by Prof. Lu Mao"
institute: 
  - "Department of Biostatistics and Medical Informatics"
  - "University of Wisconsin - Madison"
date: "2023-05-26"
header-includes:
  \usepackage[dvipsnames]{xcolor}
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["uwm", "uwm-fonts"]
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE, htmltools.preserve.raw = FALSE)
```

```{r xaringan-extra, echo=FALSE}
xaringanExtra::use_tile_view()
xaringanExtra::use_panelset()
xaringanExtra::use_tachyons()
xaringanExtra::use_progress_bar(color = "#ea5455", location = "top", height = "10px")

xaringanExtra::style_panelset_tabs(
  active_foreground = "#0051BA",
  hover_foreground = "#d22")
```

# Outline

1. Introduction and Motivation

  - INVESTED trial 
  
  - Composite endpoints

2. Complex time-to-event data under non-randomized cohorts <span style='font-size:13pt; color:#707070'> (Wang et al., 2023+, Stats in Med)</span>

3. Win ratio statistics 

  - Win ratio estimand and estimation <span style='font-size:13pt; color:#707070'> (Wang et al., 2023, JBR; Wang et al., 2023+, Under Review)</span>
  
  - Stratified win ratio regression <span style='font-size:13pt; color:#707070'> (Mao and Wang, 2021, Biometrics; Wang and Mao, 2022, Stats in Med)</span>
  
4. Survival tree for complex life history data

5. Summary

???
Here is brief outline of my presentation. I will first introduce the background and motivation. I will introduce the special design in the INVESTED trial and how to use causal inference method to analyze the data. I will talk about what is composite endpoints and how to use win ratio and survival tree to analyze prioritized composite endpoints.

---
class: inverse, center, middle

## .fancy[Chapter 1.] Introduction and Motivation

---
# INVESTED Trial

**Objective** : a multi-season trial that compares high-dose vs standard-dose influenza vaccines in reducing all-cause death or cardiopulmonary (CP) hospitalization in high-risk cardiovascular patients <span style='font-size:13pt; color:#707070'> (Vardeny et al., 2021)</span>

--

**Design** : randomize-once strategy

  - patients enrolled from previous seasons who stay alive and remain in the study will be treated according to the initial randomization in subsequent seasons.

???

The researcher will follow the patients for up to three influenza season. If the patients return to the next season, they will be re-vaccinated according to their initial randomiztion.
Only randomize new patients, the returning patients will be re-vaccinated according to their initial randomization.

--

**Primary endpoint** : time to all-cause death or CP hospitalization 
  - Modified intent-to-treat (mITT) analysis
  
    - Outcome events counted within each enrolling season

???

mITT: The study protocol proposes to use a modified intention-to-treat (mITT) analysis in which patients’ clocks will be reset at vaccination in each season, and the primary endpoint, a composite of death and CP hospitalization, will be counted until the end of that season.

--

**Challenges in statistical inference**

  - Returning subjects .uw-anchor-color[no longer comparable] between standard-dose and high-dose due to selective attrition (death/dropout)
  
  - .uw-anchor-color[Prioritized composite endpoints] 

???
The INVESTED trial is a ...[objective] 
The INVESTED trial uses the randomize-once strategy.
The INVESTED trial poses two statiscal challenges. First, the returning subjects.... Second, we need new methods to better analyze the composite endpoint.

Because of this randomization-once strategy, cohorts containing returning patients are non-randomized. 

---
# Composite Endpoints

--

#### Composite endpoints include two or more types of related clinical events 

--

- Common in cardiovascular (CV) clinical trials and cancer clinical trials
  
  - CV trials: death, heart failure, myocardial infarction, stroke, and hospitalization

- Increase number of events, increase statistical efficiency, reduce sample size

--

#### Traditional Methods on Composite Endpoints

--

- Focus on time to the first event (TFE)

- Ignore the hierarchical structure 

- Assume death and non-fatal events are equally important

???
The direct advantage of using composite endpoint is increasing the number of events. Although composite endpoints are considered to better capture the complexity of the disease process, they raise considerable challenges for interpretation and statistical analysis.

Why composite endpoints: 1. mortality rate is low. 2. The complexity of a disease may be not adequately characterized by a single outcome.

mortality for cardiovascular disease has been declining for the past decade, very large sample sizes are required to detect differences in deaths among trial groups.

---
class: inverse, center, middle

## .fancy[Chapter 2.] Complex time-to-event data under non-randomized cohorts

---
# Non-randomized cohorts <span style='font-size:18pt; color:black'> `r icons::fontawesome("arrow-circle-right")` </span> <span style='font-size:23pt; color:black'> Challenges </span>  

       
.pull-left[
#### Two statistical challenges

- Returning subjects .uw-anchor-color[no longer comparable] between standard-dose and high-dose due to selective attrition (death/dropout)

- .uw-anchor-color[Correlation] of outcomes within subject across multiple seasons


.bold[Methods]

- Inverse probability of treatment weighting, *IPTW* <span style='font-size:13pt; color:#707070'> (Xie, and Liu, 2005)</span> 

  - *propensity score* : traditional methods rely on parametric models, e.g. logistic regression <span style='font-size:13pt; color:#707070'> (Austin, 2011;  Hernán and Robins, 2020;)</span> 


 

]

.pull-right[

.panelset[

.panel[.panel-name[ Cohort ]

```{r, echo=FALSE, out.width='120%', fig.align='center'}
knitr::include_graphics('figures/chap2/cohort.png')
```
]

.panel[.panel-name[ Example ]

```{r, echo=FALSE, out.width='120%', fig.align='center', fig.cap=' -- : sicker patients; + : healthier patients'}
knitr::include_graphics('figures/chap2/cohort_example.png')
```
]

]

]

???

Logistic regression is inappropriate for the INVESTED trial because the propensity to enroll in future
seasons depends crucially on the time from randomization to the start of the current season.

---
# Methods

--

.bold[Notations]

--

- $\boldsymbol{Y}_k=(T_k, C_k, \widetilde T_k, \widetilde C_k)$, $\quad k=1,2,3$
  
  - $T_k$ primary efficacy endpoint; $C_k$ censoring time for the primary endpoint
  
  - $\widetilde T_k$ time to death or dropout; $\widetilde C_k$ administrative censoring time
  
  - $T_2$ or $C_2$ can be observed only if $\widetilde T_1>\widetilde C_1$
  
  - Similarly, $T_3$ or $C_3$ can be observed only if $\widetilde T_1>\widetilde C_1$  and
$\widetilde T_2>\widetilde C_2$

--

- Covariates $\boldsymbol{Z}_k = (\boldsymbol{Z}, \boldsymbol{Z}_k^*)$

  - $\boldsymbol{Z}$ is **baseline** characteristics: randomization status, demographic and clinical characteristics
  
  - $\boldsymbol{Z}_k^*$ ( $\boldsymbol{Z}_1^* \equiv 0$ ) contains **season-specific** variables 


???

administrative censoring: either survive or death at study observation end
loss to follow-up: the information about the subjects would have experienced at the end of the study
is unknow.

---
# Methods 

--

.pull-left[
.bold[Assumptions]

**(C1)** The relationship among the season-specific data follows the directed acyclic graph]

.pull-right[<center><img src="figures/chap2/dag.png" width="32%" /></center>]

--

**(C2)** Time to efficacy endpoint and the corresponding censoring are conditionally independent given the randomization status $A$, i.e., $(T_k \perp \!\!\! \perp C_k)\mid A$.

--

**(C3)** Time to attrition and the corresponding censoring are conditionally independent given the covariates, i.e., $(\widetilde T_k \perp \!\!\! \perp \widetilde C_k)\mid \boldsymbol{Z}_k$.

--

.bold[Remark]

- Conditions **(C2)** and **(C3)** are standard .uw-anchor-color[independent censoring assumptions]

--

- Condition **(C1)** is a season-specific version of the .uw-anchor-color[“no unmeasured confounders”] assumption <span style='font-size:13pt; color:#707070'> (Rosenbaum and Rubin, 1983)</span> 

???

The confounders influencing both re-vaccinations and the outcomes in returning seasons are fully captured in the covariates for the current season.
The association between the outcomes of the current season and the attrition from previous seasons is accounted for by the covariates.

---
# Methods <span style='font-size:18pt; color:black'> `r icons::fontawesome("arrow-circle-right")` </span> <span style='font-size:23pt; color:black'> IPTW </span>  

Define the season-specific propensity scores: $$S_1(t\mid \boldsymbol{Z}_1)= \text{pr} (\widetilde T_1>t\mid \boldsymbol{Z}_1), \quad S_2(t\mid \boldsymbol{Z}_1, \boldsymbol{Z}_2)= \text{pr}(\widetilde T_2>t\mid \boldsymbol{Z}_1, \boldsymbol{Z}_2).$$

--

**Proposition** : Under conditions (C1) and (C3), for an arbitrary function $f(\cdot)$, we have that
$$\begin{equation}
E\left\{w_1f(T_2, C_2)\right\}=E\left\{f(T_2, C_2)\right\}
\end{equation}$$
and 
$$\begin{equation}
E\left\{w_1w_2f(T_3, C_3)\right\}=E\left\{f(T_3, C_3)\right\},
\end{equation}$$
where
$$w_1=\frac{I(\widetilde T_1>\widetilde C_1)}{S_1(\widetilde C_1\mid \boldsymbol Z_1)}\mbox{ and } w_2=\frac{I(\widetilde T_2>\widetilde C_2)}{S_2(\widetilde C_2\mid \boldsymbol Z_1, \boldsymbol Z_2)}.$$

???

Therefore, we have the following proposition. Here w1 and w2 are the inverse propensity scores.

---
# Methods <span style='font-size:18pt; color:black'> `r icons::fontawesome("arrow-circle-right")` </span> <span style='font-size:23pt; color:black'> IPTW </span>  

- The selection biases in the returning non-randomized cohorts can be corrected by inverse probability of treatment weighting $\{S_1(t\mid \boldsymbol{Z}_1)\}^{-1}$ and $\{S_1(t\mid \boldsymbol{Z}_1)S_2(t\mid \boldsymbol{Z}_1, \boldsymbol{Z}_2)\}^{-1}$.

--

- Suppose there are $n$ subjects, $E\left\{f(T_2, C_2)\right\}$ can be estimated by 
$$\frac{1}{n} \sum_{i=1}^{n} \frac{ \color{blue}{I(\widetilde T_{1i}>\widetilde C_{1i})} }{S_1(\widetilde C_{1i}\mid \boldsymbol Z_{1i})} f(T_{2i}, C_{2i})$$

--

- $E\left\{f(T_3, C_3)\right\}$ can be estimated by 
$$\frac{1}{n} \sum_{i=1}^{n} \frac{ \color{blue}{I(\widetilde T_{1i}>\widetilde C_{1i})} }{S_1(\widetilde C_{1i}\mid \boldsymbol Z_{1i})} \frac{\color{green} {I(\widetilde T_{2i} >\widetilde C_{2i})} }{S_2(\widetilde C_{2i}\mid \boldsymbol Z_{1i}, \boldsymbol Z_{2i})} f(T_{3i}, C_{3i})$$

--

- $S_1(t\mid \boldsymbol Z_1)$ and $S_2(t\mid \boldsymbol Z_1, \boldsymbol Z_2)$ are estimated by the Cox proportional hazards models for attrition endpoints to obtain the estimated weights $\widehat w_1$ and $\widehat w_2$

--

- By (C2), we can fit **weighted Kaplan-Meier curves** or **weighted Cox models** for valid efficacy analysis

---
# Methods <span style='font-size:18pt; color:black'> `r icons::fontawesome("arrow-circle-right")` </span> <span style='font-size:23pt; color:black'> variance estimation </span>  

--

#### Variance estimation

- Biases with standard variance estimates

--

  - within-subject correlation across multiple seasons

--

  - additional randomness in the estimated propensity scores

--

- Solution: **Bootstrap variance estimation** <span style='font-size:13pt; color:#707070'> (Austin, 2016)</span>

  - suppose there are $n_k$ new patients enrolled in season $k$ ( $k=1, 2, 3$ )
  
  - sample with replacement $n_k$ patients in each season $k$ for $B$ times (e.g. $B=1,000$)
  
  - keep their outcome data from subsequent seasons as a subject profile

---
# Methods <span style='font-size:18pt; color:black'> `r icons::fontawesome("arrow-circle-right")` </span> <span style='font-size:23pt; color:black'> variance estimation </span>  

#### Bootstrap variance estimation

--

- Denote the parameter of interest $\theta$ (survival function at a time point or log-hazard ratio) with $\widehat{\theta}$ as the estimate

--

- For each bootstrap sample $j = 1, \ldots, B$, the **IPTW is repeated** to obtain the estimator $\widehat{\theta}_j$

--

- the bootstrap variance estimator is obtained by
$$\widehat{\text{Var}}(\widehat{\theta}) = \frac{1}{B-1}\sum_{j=1}^{B} \left( \widehat{\theta}_j - \frac{1}{B}\sum_{j=1}^{B}\widehat{\theta}_j \right)^2$$

--

- For each bootstrap sample, the **propensity score model is re-estimated** based on the attrition endpoint

  - capture the randomness in the estimation of propensity scores.

---
# Simulation

--

- Focus on Year 1 cohort

--

- For the $k$-th season, four latent event times are of interest

  - $T_{kD}$ time to death 
  
  - $T_{kH}$ time to first CP hospitalization 
  
  - $C_{kL}$ time to dropout (loss to follow-up) 
  
  - $C_{kM}$ the administrative censoring time 

  - $T_k = T_{kD} \land T_{kH}$, $C_k = C_{kL} \land C_{kM}$, $\widetilde{T}_k = T_{kD} \land C_{kL}$, and $\widetilde{C}_k = C_{kM}$
  
--

- Treatment $A \sim \text{Bernoulli(0.5)}$ 
  
- Sample size $n=1,000$ with $2,000$ replicates
  
- Number of bootstrap sample $B = 50$

---
# Simulation

--

- $Z \sim \text{Uniform}[0, 1]$, $Z_k^* \sim \text{Poisson}(2+3A)$ for $k = 2, 3$ and ${Z}_1^* \equiv 0$

--

- $T_{kH} \sim \text{Expn}(\eta \exp(\mu A))$

- $T_{kD} \sim \text{Expn}\left( (\gamma Z + \delta Z_k^*) \exp(\mu A)\right)$

--

- $C_{kM} \sim \text{Uniform}[1, 6]$, $C_{kL} = \infty$

--

- Fix $\gamma = 0.2$, $\eta = 0.05$, $\delta = 0.01$, and $\mu=0.2$

- Around 70% and 45% subjects return to season 2 and 3, respectively. 

- The true survival function for TFE in season $k$ for treatment $A$ is
$$P(T_k > t | A) = e^{-\eta\exp(\mu A)t}\left(\int_{0}^{1}e^{-\gamma z \exp(\mu A)t}\text{d}z\right) e^{(2+3A)(\exp(-\delta \exp(\mu A) t)-1)}$$
???
Under this set-up, we can calculate the true survival function on T_k. Therefore, we can compare the IPTW method with the true true survival function

---
# Simulation

.panelset[

.panel[.panel-name[ Season 2 KM curves ]

```{r, echo=FALSE, out.width='75%', fig.align='center'}
knitr::include_graphics('figures/chap2/new/sim2-a2.png')
```
]

.panel[.panel-name[ Season 2 CI]

```{r, echo=FALSE, out.width='75%', fig.align='center'}
knitr::include_graphics('figures/chap2/new/sim2-b2.png')
```

]

.panel[.panel-name[ Season 3 KM curves ]

```{r, echo=FALSE, out.width='75%', fig.align='center'}
knitr::include_graphics('figures/chap2/new/sim2-a3.png')
```
]

.panel[.panel-name[ Season 3 CI]

```{r, echo=FALSE, out.width='75%', fig.align='center'}
knitr::include_graphics('figures/chap2/new/sim2-b3.png')
```

]

]

---
# Simulation

#### Simulation results for selected time points for control group in season 3

```{r, echo=FALSE}
df <- data.frame(
  
  t = c(1.0, 2.0, 3.0, 4.0),
  St = c("0.845", "0.717", "0.610", "0.521"),
  BIAS = c(0.018, 0.031, 0.039, 0.044),
  SE = c(0.021, 0.028, 0.033, 0.038),
  SEE = c(0.021, 0.028, 0.033, 0.037),
  CP = c(0.899, 0.836, 0.808, 0.786),
  IPTW_BIAS = c(0.001, 0.002, 0.002, 0.003),
  IPTW_SE = c(0.027, 0.034, 0.039, 0.044),
  NAIVE_SEE = c(0.016, 0.021, 0.024, 0.027),
  NAICE_CP = c(0.762, 0.762, 0.767, 0.765),
  BOOT_SEE = c(0.027, 0.034, 0.038, 0.042),
  BOOT_CP = c(0.943, 0.947, 0.941, 0.941)
)

sketch = htmltools::withTags(table(
  class = 'display',
  thead(
    tr(
      th(rowspan = 3, 't'),
      th(rowspan = 3, 'S(t)'),
      th(rowspan = 2, colspan=4, '<span style="color:#b83b5e">Unweighted</span>'),
      th(colspan = 6, '<span style="color:#386cb0">IPTW</span>')
    ),
    tr(
      th(colspan = 2, ''),
      th(colspan = 2, '<span style="color:#F6416C">Naive</span>'),
      th(colspan = 2, '<span style="color:#F08A5D">Bootstrap</span>')
    ),
    tr(
      lapply(c('Bias', 
               'SE', 
               'SEE', 
               'CP',
               'Bias', 
               'SE', 
               '<span style="color:#F6416C">SEE</span>', 
               '<span style="color:#F6416C">CP</span>',
               '<span style="color:#F08A5D">SEE</span>', 
               '<span style="color:#F08A5D">CP</span>'), th)))))

library(DT)
DT::datatable(
  df, container = sketch, options = list(dom = 't'), 
  rownames = FALSE, escape = FALSE)
```

.fancy[Note]: .bold[SE] is standard error of the survival function estimator; .bold[SEE] is the mean of the standard error estimator; .bold[CP] is the coverage probability of the 95% confidence interval.


---
# Example: INVESTED trial

.pull-left[

- 5,209 subjects and 7,153 subject-seasons over three influenza seasons

- Two treatment groups: **High-dose (HD-TIV)** vs **Standard-dose (SD-QIV)**

- Primary outcome: time to death or CP hospitalization 

- Baseline covariates: 
  - qualifying event
  - history of renal impairment
  - history of ischemic stroke
  - prior myocardial infarction

- Season-specific covariates:
  - CP hospitalization event rate 

]

.pull-right[
```{r, echo=FALSE, out.width='100%', fig.align='center', fig.cap="Number of subjects by vaccination groups ([HD-TIV : SD-QIV]) in the INVESTED trial"}
knitr::include_graphics('figures/chap2/invested.png')
```
]

---
# Example: INVESTED trial

.panelset[

.panel[.panel-name[ KM curves ]

```{r, echo=FALSE, out.width='75%', fig.align='center'}
knitr::include_graphics('figures/chap2/new/invested-km.png')
```
]

.panel[.panel-name[ KM CIs]

```{r, echo=FALSE, out.width='75%', fig.align='center'}
knitr::include_graphics('figures/chap2/new/invested-ci.png')
```

]

.panel[.panel-name[ Hazard ratio ]

- Treatment effect: Hazard ratio (HR)

  - Unadjusted Cox model stratified by enrolling season

  - only include the treatment assignment in the Cox model

```{r, echo=FALSE}
df <- data.frame(
  HR = '<span style="color:#b83b5e">1.06</span>',
  CI = "0.97–1.16",
  p = "0.18",
  HR = '<span style="color:#386cb0">1.07</span>',
  CI = "0.99–1.15",
  p = "0.11",
  CI = "0.90–1.25",
  p = "0.44"
)

sketch = htmltools::withTags(table(
  class = 'display',
  thead(
    tr(
      th(rowspan = 2, colspan=3, '<span style="color:#b83b5e">Unweighted</span>'),
      th(colspan = 5, '<span style="color:#386cb0">IPTW</span>')
    ),
    tr(
      th(colspan = 1, ''),
      th(colspan = 2, '<span style="color:#F6416C">Naive</span>'),
      th(colspan = 2, '<span style="color:#F08A5D">Bootstrap</span>')
    ),
    tr(
      lapply(c('HR', 
               '95% CI', 
               'P-value', 
               'HR', 
               '<span style="color:#F6416C">95% CI</span>', 
               '<span style="color:#F6416C">P-value</span>', 
               '<span style="color:#F08A5D">95% CI</span>', 
               '<span style="color:#F08A5D">P-value</span>'), th)))))

library(DT)
DT::datatable(
  df, container = sketch, 
  options = list(dom = 't',
                 columnDefs = list(list(className = 'dt-center', targets = 0:7))), 
  rownames = FALSE, escape = FALSE)
```

]

]

???
The difference between the IPTW and unweighted results for the INVESTED data is minor because the two vaccines don’t have a significantly differential effect on the attrition endpoints. As illustrated in the simulation section, when the treatment has a significant effect on the attrition endpoints, the unweighted analyses could be biased for later seasons, while the IPTW analyses correct the biases.

---
# Summary

--

<br>

- The proposed methods are motivated by the special design in the INVESTED trial

  - **Survival models** to estimate propensity scores
  
  - **Bootstrap variance estimation** to account for the randomness in the estimated weights

--

- Simulation studies show that

  - the proposed IPTW method produce unbiased estimates of .uw-anchor-color[survival functions] or .uw-anchor-color[hazard ratios]
  
  - the bootstrap variance estimation produce accurate variance estimates

--
  
- Data from the INVESTED trial are used for illustration

- Applicable to other randomize-once multi-season trials


???
The difference between the IPTW and unweighted results for the INVESTED data is minor because the two vaccines don’t have a significantly differential effect on the attrition endpoints. As illustrated in the simulation section, when the treatment has a significant effect on the attrition endpoints, the unweighted analyses could be biased for later seasons, while the IPTW analyses correct the biases.

---
class: inverse, center, middle

## .fancy[Chapter 3.] Win ratio statistics

???

Composite endpoints usually comprise components of unequal importance and should therefore be properly prioritized. For instance, death is in general considered much more severe than other non-fatal events such as hospitalization. Traditional approach to analyze composite endpoints has a major limitation, that is, it focuses on time to the first event and thus  death and non-fatal events are equally important. Win ratio is simple and novel alternative approach to better analyze prioritized composite endpoints.


---
# Win statistics

--

- .bold[General pairwise comparisons]: compare every patient in the treatment with every one in the control

--

- Within each pair

  - Decide a "win", a "lose" or a "tie"
  
  - First compare on the most important event: time to death 
  
  - If the comparison is inconclusive due to censoring, proceed to the second most important event

--

<img src="figures/chap3/Adeath.jpg" width="32%" />
--
<img src="figures/chap3/Ahosp.jpg" width="32%" />
--
<img src="figures/chap3/tie.jpg" width="32%" />

---
# Win statistics

--

Define

- $N_t$ and $N_c$: number of subjects in treatment and control group

- $n_t$ and $n_c$: number of wins by treatment and control group

--

- $P_t = \frac{n_t}{N_tN_c}$: proportions of pairs when treatment wins

- $P_c = \frac{n_c}{N_tN_c}$: proportions of pairs when control wins

- $P_{\text{tie}} = 1-P_t-P_c$: proportions of ties

--

The treatment effect can be quantified by a series of win statistics:

- net benefit </span><span style='font-size:13pt; color:#707070'> (Buyse, 2010) </span> : $P_t - P_c$

- **win ratio** </span><span style='font-size:13pt; color:#707070'> (Pocock, 2012) </span>: ${P_t}/{P_c}$

- win odds </span><span style='font-size:13pt; color:#707070'> (Dong, 2020) </span>: $(P_t + 0.5P_{\text{tie}})/(P_c + 0.5P_{\text{tie}})$

---
# Win Ratio

#### Challenge 1

- The true value (estimand) of win ratio depends on the censoring distribution and the maximum follow-up time

--

$\hspace{3cm}$<img src="figures/chap3/Adeatht1.jpg" width="35%" />
--
<img src="figures/chap3/Adeatht2.jpg" width="35%" />

--

> ICH E9 (R1): "...missing data and loss-to-follow-up are irrelevant to the construction of the estimand." <span style='font-size:13pt; color:#707070'> (ICH E9 (R1), 2020)</span> 

---
# Win Ratio

--

#### Challenge 2

- Previous work on win ratio focus on two-sample comparison

--

- **Regression framework vs. two-sample comparison:**

  - Covariate adjustment
  
  - Statistical efficiency 

  - Subgroup analysis 

  - Adjusting confounders (observational studies)

---
# Win Ratio <span style='font-size:23pt; color:black'> General Framework</span>

.bold[Notations]

- $D$: survival time and $N_D(t) = I(D\leq t)$ 

- $N_1(t),\ldots,N_K(t)$ denote the counting processes of $K$ non-fatal
events ordered by importance

- $\bar{N}(t) = \{N(u):0\leq u\leq t\}$ : event-history process

- $Y_1(t), \ldots, Y_J(t)$ : $J$ longitudinal variables measured at time $t$

- Covaraite history $\bar{Y}_j(t) = \{Y_j(u): 0 \leq u \leq t\}$ 

- $\boldsymbol{Y}(t) = \left\{ \bar{N}_D(t),\bar{N}_1(t),\ldots,\bar{N}_K(t), \bar{Y}_1(t), \ldots, \bar{Y}_J(t) \right\}$

- For all notations, we use subscripts $i$ and $j$ to denote the corresponding values from subjects $i$ and $j$

- $\tau$: maximum follow-up time or user specified time

???

First, let me introduce some necessary notations. Let D denote survival and N_D is the counting process of Death, which is an indication function. Let N1 to Nk represent the counting processes of K non-fatal events. Let N bar t represent the event history process. We also consider some longitudinal data as well. Let Yt be the set of all the event history processes. Note that for all these notations, we will use subscripts i and j to represent different subjects.

---
#  Win Ratio <span style='font-size:18pt; color:black'> `r anicon::faa("arrow-circle-right", animate="float", speed="slow")`  </span> <span style='font-size:23pt; color:black'> General Framework</span>

--

.bold[Win function]

--

Define the win indicator function for two independent subjects with
$\boldsymbol{Y}_{i}$ and $\boldsymbol{Y}_{j}$ as  </span><span style='font-size:13pt; color:#707070'> (Mao and Wang, 2021) </span>
<span style='color:#0479a8'>
$$\mathcal{W}(\boldsymbol{Y}_{i},\boldsymbol{Y}_{j})(t) = I(\boldsymbol{Y}_{i} \text{ wins over }\boldsymbol{Y}_{j}\text{ up to time } t).$$</span>

--

$\mathcal{W}(\cdot,\cdot)$ satisfies the following three conditions for every $t \in [0, \tau]$:

-   (W1) $\mathcal{W}(\boldsymbol{Y}_{i},\boldsymbol{Y}_{j})(t)$ is a
    function of $\boldsymbol{Y}_{i}(t)$ and $\boldsymbol{Y}_{j}(t)$ only;

--

-   (W2) $\mathcal{W}(\boldsymbol{Y}_{i},\boldsymbol{Y}_{j})(t) + \mathcal{W}(\boldsymbol{Y}_{j},\boldsymbol{Y}_{i})(t) = 0 \text{ or } 1;$

--

-   (W3) $\mathcal{W}(\boldsymbol{Y}_{i},\boldsymbol{Y}_{j})(t) = \mathcal{W}(\boldsymbol{Y}_{i},\boldsymbol{Y}_{j})(D_{i} \land D_{j} \land t)$.

--

Examples of win functions: sequential comparison in win ratio, comparison on time to the first event.

???
First Win function is a function of of Yi(t) and Yj(t), this means we compare two subjects at the same time point.
The second condition requires that there is only zero or one winner between two independent subjects.
Third, we require the the value of the win function stays constant after either subject i or j die.
People can define there own functions and it is reasonable as long as the win functions satisfy these three requirement. 

---
# Restricted Time Win Ratio <span style='font-size:18pt; color:black'> `r icons::fontawesome("arrow-circle-right")` </span> <span style='font-size:23pt; color:black'> Definition </span>  
--

<b><span style='color:#ea5455'>Estimand</span></b> : the restricted time win ratio (RTWR) for multivariate hierarchical variables can be defined as <span style='font-size:13pt; color:#707070'> (Wang et al., 2023+) </span>
<span style='color:#0479a8'>
$$\mbox{RTWR}(\tau) = \frac{\text{E}\{ \mathcal{W}(\boldsymbol Y^{(1)}, \boldsymbol Y^{(0)})(\tau)\}}{\text{E}\{ \mathcal{W}(\boldsymbol Y^{(0)}, \boldsymbol Y^{(1)})(\tau)\}},$$</span>
where $\boldsymbol{Y}^{(a)}$ denote the potential outcome under group $a$ ( $0$ : control, $1$ : treatment )

--

<b><span style='color:#ea5455'>Interpretation</span></b>:  number of times subjects in the treatment are likely to have a favorable outcome compared to those in the control by time $\tau$

--

<b><span style='color:#ea5455'>Estimation</span></b> 
  
  - For univariate case, the RTWR can be estimated by integral approach using Kaplan-Meier estimators
  
  - For multivaraite case, estimation using the distribution of the variables could be complex

---
# Restricted Time Win Ratio <span style='font-size:18pt; color:black'> `r icons::fontawesome("arrow-circle-right")` </span> <span style='font-size:23pt; color:black'> Estimation </span>

--

### Imputation

--

- Impute the response outcomes up to time $\tau$

--

$\hspace{3cm}$<img src="figures/chap4/imp1.jpg" width="35%" />
--
<img src="figures/chap4/imp2.jpg" width="43%" />

--

- **Advantages:**  Estimation of the win ratio is fairly easy if all data are observed.

---
# Multiple imputation

--

.bold[Joint imputation for longitudinal outcomes and clinical events] <span style='font-size:13pt; color:#707070'> (Wang et al., 2023, JBR) </span>

--

- **Challenges:** Variables in $\boldsymbol{Y}$ are of different types

--

- Fully conditional specification <span style='font-size:13pt; color:#707070'> (Van Buuren, 2006) </span>

--

- Partition the data. A natural choice to partition the data is by the time points that the longitudinal data are measured, i.e. $0 = t_0 < t_1 < \ldots < t_K = \tau$

--

- Within in each time interval $(t_{k-1}, t_k]$, the missing data can be imputed through a series of conditional distribution

--

  - impute *death time* using a parametric proportional hazard model

--

  - impute *recurrent events* using poisson process with constant rate, the rate can be estimated by negative binomial model

--

  - impute *longitudinal variable* using a linear regression or logistic regression



---
# Example: HEART2D study

--

**HEART2D study** <span style='font-size:13pt; color:#707070'> (Raz et al., 2009) </span> :  compare two insulin strategies, **PRANDIAL** (treatment) vs **BASAL** (control), on the composite of CV death, nonfatal CV events:
  - myocardial infarction, stroke, coronary revascularization, hospitalized acute coronary syndrome

--

  - log-rank test on time to the first CV event: HR 0.98 (95 % CI: 0.8-1.21)

--

**Study sample**: 1,006 patients (treatment: 490; control: 516)

--

.pull-left[
**Win ratio**: death  <span style='font-size:14pt; color:black'> `r icons::fontawesome("long-arrow-alt-right")` </span> number of non-fatal CV events  <span style='font-size:14pt; color:black'> `r icons::fontawesome("long-arrow-alt-right")` </span> time to first non-fatal CV event <span style='font-size:14pt; color:black'> `r icons::fontawesome("long-arrow-alt-right")` </span> at least 0.3% HbA1c improvement 

**Imputation:**  Impute the data sequentially based on clinical visit of measuring HbA1c

**Inference:** Rubin's formula to combine 50 imputed data

]

.pull-right[

```{r, echo=FALSE}

df <- data.frame(
  
  Time = c(78, 104, 130, 156, 182),
  WR = c(1.035, 1.055, 1.071, 1.134, 1.153),
  pvalue = c(0.721, 0.568, 0.467, 0.172, 0.163)
  
)

DT::datatable(
  df, 
  options = list(dom = 't',pageLength = 10,
                 columnDefs = list(list(className = 'dt-center', targets = 0:2))), 
  rownames = FALSE, escape = FALSE,
  colnames = c("Time (weeks)", "Win Ratio", "P-value"))

```
]
---
# Win Ratio Regression <span style='font-size:18pt; color:black'> `r icons::fontawesome("arrow-circle-right")` </span> <span style='font-size:23pt; color:black'> Formulation </span>

--

Define $\boldsymbol{Z} \in \mathbb{R}^p$ a vector of baseline covariates, the **proportional win-fractions (PW) regression** models <span style='font-size:13pt; color:#707070'> (Mao and Wang, 2021, Biometrics)</span>
<span style='color:#0479a8'>
$$\frac{E\left\{\mathcal{W}(\boldsymbol{Y}_{i},\boldsymbol{Y}_{j})( t ) | \boldsymbol{Z}_{i}, \boldsymbol{Z}_{j}\right\}}{E\left\{\mathcal{W}(\boldsymbol{Y}_{j},\boldsymbol{Y}_{i})( t ) | \boldsymbol{Z}_{i}, \boldsymbol{Z}_{j}\right\}} =\exp \left\{\boldsymbol{\beta}^{\mathrm{T}}\left(\boldsymbol{Z}_{i}-\boldsymbol{Z}_{j}\right)\right\}$$</span>

--

- <b><span style='color:#ea5455'> Interpretation: </span></b> $\beta_k$ can be interpreted as the log win ratio associated with a one-unit increase in covariate $Z_k$ when the other predictors are fixed

--

- <b><span style='color:#ea5455'> Assumption: </span></b> Covariate-specific win and loss fractions are proportional over time

--

- Equivalent to a Cox PH model on TFE if $\mathcal{W}$ is defined as the comparison on the TFE. 

???

This model is similar to logistic regression and cox model.

Under the model, the covariate-specific win and loss fractions are proportional over time, that is the win ratio remain constant over time. This proportionality assumption is very similar with the proportional hazard assumption in cox ph model. Actually, our model can be degenerated to a cox ph model under some certain condition. 

Pocock two sample win ratio is a special case with Z being binary and one-dimensional.


---
class: center, middle

<span style='font-size:25pt; color:#ea5455'> What if proportionality assumption fails? </span>

--

<span style='font-size:18pt; color:black'> `r anicon::faa("arrow-circle-right", animate="passing", size=1.2)` Stratify on nonproportional covariates </span>

???

However, in practice, the proportionality assumption may not always hold for all predictors.
What should we do if the proportionality assumption fails. One way to solve  this problem is stratification. It is commonly used in many clinical trials. When the proportional hazards assumption does not hold, the stratified Cox model and the stratified Fine-Gray model are recommended for time-to-first-event analyses and competing risks data.

---
# The stratified PW models <span style='font-size:18pt; color:black'> `r icons::fontawesome("arrow-circle-right")` </span> <span style='font-size:23pt; color:black'> Formulation</span>

--

- Stratified variable : $L$ levels

- $li$ and $lj$ denote the corresponding values from subjects $i$ and $j$ in stratum $l = 1,\ldots,L$

--

A **stratified proportional win-fractions (PW) model** can be
formulated as <span style='font-size:13pt; color:#707070'> (Wang and Mao, 2022, Stats in Med)</span>

<span style='color:#0479a8'>
$$\mathcal{R}\left(t \mid \boldsymbol{Z}_{l i}, \boldsymbol{Z}_{l j} ; \mathcal{W}\right) \equiv \frac{E\left\{\mathcal{W}(\boldsymbol{Y}_{li},\boldsymbol{Y}_{lj})(t) | \boldsymbol{Z}_{li}, \boldsymbol{Z}_{lj}\right\}}{E\left\{\mathcal{W}(\boldsymbol{Y}_{lj},\boldsymbol{Y}_{li})(t) | \boldsymbol{Z}_{li}, \boldsymbol{Z}_{lj}\right\}} =\exp \left\{\boldsymbol{\beta}^{\mathrm{T}}\left(\boldsymbol{Z}_{l i}-\boldsymbol{Z}_{l j}\right)\right\} \quad(l=1, \ldots, L).$$
</span>
where
$\boldsymbol{\beta} = (\beta_1, \ldots, \beta_p)^T$ is a $p$-dimensional
regression parameters shared by all $L$ groups.

--

- <b><span style='color:#ea5455'> Interpretation: </span></b> same as PW model

--

- <b><span style='color:#ea5455'> Assumption: </span></b> Covariate-specific win and loss fractions are proportional over time **within each stratum**

--

- Equivalent to a stratified Cox PH model on TFE if $\mathcal{W}$ is defined as the comparison on the TFE. 

---
# The stratified PW models 

.panelset[

.panel[.panel-name[ Check assumption ]



.bold[Check proportionality]:

  - Plot residuals (observed vs model-based win-fractions) over time 
  
  - Should fluctuate around zero without any systemic pattern
  
  - Example: ACCORD trial <span style='font-size:13pt; color:#707070'> (Raz et al., 2009) </span>

```{r, echo=FALSE, out.width='60%', fig.align='center'}
knitr::include_graphics('figures/chap3/proportionality.png')
```

  - Stratify on nonproportional covariate: `sex`


]

.panel[.panel-name[ACCORD results]
.left-column[

- Sex-stratified analysis

- WR for treatment: 1.17

]

.right-column[
```{r, echo=FALSE}
df <- data.frame(
  variable = c(
  "Fibrate vs Placebo", "Intensive vs Standard", 
  "Baseline age",  "White vs Non-white", 
  "Glycated hemoglobin", "Plasma triglyceride",
  "LDL cholesterol", "HDL cholesterol"),
  WR = c('<span style="color:#dc2f02">1.17</span>', "0.87", "0.97", "0.86", "0.93", "1.00", "1.00", "1.04"),
  CI = c( '<span style="color:#dc2f02">(0.90, 1.51)</span>', "(0.67, 1.12)", "(0.96, 0.99)",
          "(0.63, 1.18)", "(0.82, 1.06)", "(1.00, 1.00)",
          "(1.00, 1.01)", "(1.01, 1.07)"),
  pvalue = c('<span style="color:#dc2f02">0.243</span>', "0.273", "0.005**", "0.360", 
             "0.308", "0.978", "0.797", "0.009**")
)

sketch = htmltools::withTags(table(
  class = 'display',
  thead(
    tr(
      th(rowspan = 2, 'Variable'),
      th(colspan = 3, 'Sex-stratified PW')
    ),
    tr(
      lapply(c("WR", "95%CI", "P-value"), th)
    )
  )
))

library(DT)
DT::datatable(
  df, container = sketch, 
  options = list(dom = 't',pageLength = 10,
                 columnDefs = list(list(className = 'dt-center', targets = 0:3))), 
  rownames = FALSE, escape = FALSE)
```
]
]

]

---
class: inverse, center, middle

## .fancy[Chapter 4.] Survival tree for complex life history data

---
# Survival tree

--

Decision tree: Classification and Regression Tree (CART) developed by Breiman et al. (1984)

--

Survival tree: extension of decision tree methods to censored time-to-event data

--

.pull-left[

.bold[Tree terminology]

- Root node: `1`

- Internal nodes: `1`, `2`, `3`

- Terminal (Leaf) nodes: `4`, `5`, `6`, `7`

- Node `2` is a parent node 

- `4` and `5` are child nodes of node `2`

]

.pull-right[

<img src="figures/chap5/tree_example.png" width="100%" />

]

???


Decision tree is machine learning method developed for prediction, specifically for classification and regression. Survival tree is an extension of the decesion tree methods to survival data. This figure shows an example of a decision with 7 nodes. 

---
# Survival tree

--

The construction of a tree involves the following three general elements:

--

1. **Selection of the splits**, i.e., how do we decide which variable to split and how to split it? 

  - recursively partitioning the covariate space 
  
  - binary split: $I\{\text{age} < 55\}$, $\text{Diabetes history : yes or no}$
  
  - creates the most homogeneous groups with respect to the outcome variable
  
--

2. **Pre-pruning**: when to stop? 

--

3. **Post-pruning**

  - take off branches of a deep tree

  - prevent overfitting

  - more robust and accurate predictions on unseen data

---
# Survival tree <span style='font-size:18pt; color:black'> `r icons::fontawesome("arrow-circle-right")` </span> <span style='font-size:23pt; color:black'> Node splitting</span>

.bold[General procedure for node splitting]

--

Given a node $h$, define

  - $p(h)$ the probability a subject goes to node $h$ 
  
  - $\mathcal{G}(h)$ the **impurity function** within the node $h$

--
  
The optimal partition $s$ is determined by cutting a covariate $Z_j$ that maximizes the reduction in impurity, i.e., 
<span style='color:#0479a8'>
$$\Delta \mathcal{G}(s,h) = \mathcal{G}(h) - p(h_L|h)\mathcal{G}(h_L) - p(h_R|h)\mathcal{G}(h_R)$$</span>
- $h_L$ and $h_R$ are the two child nodes generated by splitting $h$

- $p(h_L|h) = p(h_L)/p(h)$ and $p(h_R|h) = p(h_R)/p(h)$ are the probabilities that any sample in node $h$ moving to the left and right nodes, respectively.



---
# Survival tree <span style='font-size:18pt; color:black'> `r icons::fontawesome("arrow-circle-right")` </span> <span style='font-size:23pt; color:black'> Node splitting</span>

--

Commonly used impurity functions $\mathcal{G}(\cdot)$: 

  - classification: Gini index, entropy
  
  - regression: mean squared error

--

For example, the **Gini index** for a categorical outcome $O \in \{1, \ldots, M\}$ within node $h$ is defined as 

$$\mathcal{G}_C(h) = \operatorname{pr}\left\{O_i \neq O_j | h\right\} = E\{I(O_i \neq O_j) | h\},$$

- $O_i$ and $O_j$ are two independent outcomes

- $\operatorname{pr}(\cdot| h)$ and $E(\cdot| h)$ are the probability or expectation within node $h$, respectively. 

---
# Survival tree <span style='font-size:18pt; color:black'> `r icons::fontawesome("arrow-circle-right")` </span> <span style='font-size:23pt; color:black'> Node splitting</span>

--

Splitting rules in survival trees can generally be classified into two main approaches <span style='font-size:13pt; color:#707070'> (Bou-Hamad et al., 2011; Bertsimas
et al., 2022)</span> 

--

  - between-node “distance” <span style='font-size:13pt; color:#707070'> (LeBlanc and Crowley, 1993; Fan et al., 2006)</span> 
  
    - maximize the difference between observations in the two child nodes 
    
    - rely on a two-sample statistics such as log-rank statistics or likelihood ratio statistics

--
  
  - within-node “purity” <span style='font-size:13pt; color:#707070'> (Therneau et al., 1990; LeBlanc and Crowley, 1992)</span> 
  
    - group similar observations within a single node to achieve homogeneity
    
    - rely on the likelihood, deviance, and martingale residuals under Cox-type models

---
class: center, middle

<span style='font-size:25pt; color:#ea5455'> Existing survival tree methods focus on time-to-first event</span>

--

<span style='font-size:18pt; color:black'> `r anicon::faa("exclamation", animate="bounce", size=1.2)` ignore the unequal severity between the component events </span>

--

<span style='font-size:18pt; color:black'> `r anicon::faa("arrow-circle-right", animate="passing", size=1.2)` need an extension to prioritized composite endpoints </span>

---
# Survival tree <span style='font-size:18pt; color:black'> `r icons::fontawesome("arrow-circle-right")` </span> <span style='font-size:23pt; color:black'> Setup and notation </span>


$Y(t)$ denote the multistate process with state space ${0, 1, \ldots, K, K+1}$

  - $0$ indicates event-free status
  
  - $K+1$ indicates the absorbing state of death
  
  - $1, \ldots, K$ indicate a series of intermediate states with increasing severity 

Progressive multistate processes : $Y(t) \leq Y(s)$ for all $0 \leq t \leq s$.

<center> <img src="figures/chap5/multistate.png" width="75%" /> </center>

---
# Survival tree <span style='font-size:18pt; color:black'> `r icons::fontawesome("arrow-circle-right")` </span> <span style='font-size:23pt; color:black'> Weighted Gini index </span>

--

.bold[Approach 1]: For a fixed time $t$, the multistate process $Y(t)$ takes value in $\{0, \ldots, K + 1\}$. 

--

The **weighted Gini index** at time t 

$$\mathcal{G}_W(h)(t) = E\left\{ L\left\{Y_i(t), Y_j(t)\right\} I\left\{Y_i(t) \neq Y_j(t) \right\} | h \right\}$$

- $L(k, l) \geq 0$ is loss function measuring the “distance” between states $k$ and $l$ 

--

To summarize the impurity across $[0,\tau]$, consider an **integrated Gini index** : 
$\mathcal{G}_W(h) = \int_{0}^{\tau} \mathcal{G}_W(h)(t) \mathrm{d} t$

--

**Challenges:** requires the specification of a loss function $L(k, l)$ and numerically determine the severity difference between higher and lower numbered states

???

**Challenges:** requires the specification of a loss function $L(k, l)$ and numerically determine the severity difference between higher and lower numbered states

---
# Survival tree <span style='font-size:18pt; color:black'> `r icons::fontawesome("arrow-circle-right")` </span> <span style='font-size:23pt; color:black'> Twoing criterion </span>

--

.bold[Approach 2]: **Twoing criterion**

--

Let $\mathcal{G}_k(h)(t)$ be the Gini index for the Bernoulli variable <span style='color:#ea5455'> $U = I\{ Y(t) > k \}$</span>

<span style='color:#0479a8'>
$$\mathcal{G}_k(h)(t) = E\left\{I(U_i \neq U_j) | h \right\} = 2 \operatorname{pr}\{Y_i(t) \leq k | h\} \operatorname{pr}\{Y_j(t) > k | h\}.$$</span>
<br>

--

To estimate $\operatorname{pr}\{Y_i(t) \leq k | h\}$, we make the following assumptions:

- (A1) The multistate processes $Y(\cdot)$ are progressive, i.e. $Y(t) \leq Y(s)$ for all $0 \leq t \leq s$, with $Y(0) = 0$;

- (A2) Death (state $K+1$) is the only absorbing state, i.e., there is no competing risk to death.

???

Assumption 1 requires that the patient always start in
state 0 and progress only forward. 

The T are proper random variables, owing to Assumption 2, the corresponding
transitioning events are not subject to competing risks and
thus always occur in finite time.

---
# Survival tree <span style='font-size:18pt; color:black'> `r icons::fontawesome("arrow-circle-right")` </span> <span style='font-size:23pt; color:black'> Twoing criterion </span>

--

Denote $T_k$ as the time of transition into state $k$ or higher

- $T_k = \inf \{ t: Y(t) \geq k\}$ $k=0, \ldots, K$ and $T_{K+1} = D$

--

- By definition, $T_1 \leq T_2 \leq \ldots \leq T_{K+1}$ with the equality achieved when some states are skipped.

--

- Because $Y(\cdot)$ is progressive, <span style='color:#0479a8'> $\{Y_i(t) < k\} \iff	\{ T_k > t\}$ </span>

--

- Write $S_k(t | h) =  \operatorname{pr}\{T_k > t | h\}$

--

We have $$\begin{align*} \mathcal{G}_k(h)(t) &= 2 \operatorname{pr}\{Y_i(t) \leq k | h\} \operatorname{pr}\{Y_j(t) > k | h\}  \\ &=  2 \operatorname{pr}\{Y_i(t) <  k+1 | h\} \operatorname{pr}\{Y_j(t) \geq k+1 | h\} \\ &= 2S_{k+1}(t|h) \left[1-S_{k+1}(t|h)\right] \end{align*}$$

---
# Survival tree <span style='font-size:18pt; color:black'> `r icons::fontawesome("arrow-circle-right")` </span> <span style='font-size:23pt; color:black'> Twoing criterion </span>

--

- To sum the impurity over $[0, \tau]$, consider <span style='color:#0479a8'> $\mathcal{G}_k(h) = \int_{0}^{\tau} \mathcal{G}_k(h)(t) \mathrm{d}t$ </span>

--

- Then the reduction in $\mathcal{G}_k(\cdot)$ after splitting $s$ is $$\Delta \mathcal{G}_k(s,h) = \mathcal{G}_k(h) - p(h_L|h)\mathcal{G}_k(h_L) - p(h_R|h)\mathcal{G}_k(h_R),$$

--

- further can be simplified 
<span style='color:#0479a8'>
$$\Delta \mathcal{G}_k(s, h) = 2 p(h_L|h) p(h_R|h) \int_{0}^{\tau}  \left[S_{k+1}(t|h_L) - S_{k+1}(t|h_R)\right]^2 \mathrm{d}t$$</span>

--

- Finally, select the split $s$ that maximizes
$$\Delta \mathcal{G}(s, h) = \max_{k=0,\ldots,K} \Delta \mathcal{G}_k(s, h)$$
--

- Under $(A1)$ and $(A2)$, $S_k(t | h)$ can be consistently estimated by the Kaplan-Meier estimator 

---
# Simulation <span style='font-size:18pt; color:black'> `r icons::fontawesome("arrow-circle-right")` </span> <span style='font-size:23pt; color:black'> Splitting performance </span>

--

- Consider progressive multistate process with $K=2$, non-fatal events $\widehat{T}_1$ and $\widehat{T}_2$ and death $D$.

  - trivariate Gumbel-Hougaard copula model: $$\operatorname{pr}\left\{ \widehat{T}_1 > t_1, \widehat{T}_2>t_2, D>s | {Z}_1 \right\} = \exp\left[ -\left\{ (\lambda_{1}  t_1)^{\kappa}+ (\lambda_{2} t_2)^{\kappa} + (\lambda_{3} s)^{\kappa} \right\}^{1/{\kappa}}  \right]$$

--

  - $Z_1 \sim \text{Uniform}[0, 2]$

  - <span style='color:#0479a8'> $\lambda_{a} = \lambda_{a0} + \mu_a I(Z_1 > \phi_a)$ </span> for $a=1,2,3$ 
  
  - $\phi_a$: control the cutoff of $Z_1$ on the latent event times

  - $\kappa$: controls the correlation between components 
  
  - Fix $\kappa = 2$,  $\lambda_{10} = 0.6$, $\lambda_{20} = 0.4$, and $\lambda_{30} = 0.3$

--

- Censoring time: $\text{Unif}[1,4] \land \text{Expn}(0.1)$

--

- Compare on the distribution of cutoff points over 1,000 replicates between **Multistate-tree** and **TFE-tree**

---
# Simulation <span style='font-size:18pt; color:black'> `r icons::fontawesome("arrow-circle-right")` </span> <span style='font-size:23pt; color:black'> Splitting performance </span>

.panelset[

.panel[.panel-name[ Scenario 1 ]

.left-column[

- $\lambda_{a} = \lambda_{a0} + \mu_a I(Z_1 > \phi_a)$ 

- $\phi_a = 0.8$ for $a=1,2,3$

- all three events share identical cutoff points on $Z_1$

]

.right-column[
```{r, echo=FALSE, out.width='85%', fig.align='center'}
knitr::include_graphics('figures/chap5/sim1-a-500.png')
```
]

]

.panel[.panel-name[ Scenario 2 ]

.left-column[

- $\lambda_{a} = \lambda_{a0} + \mu_a I(Z_1 > \phi_a)$ 

- $\phi_1=\phi_2=0.5$ and $\phi_3=1.5$

- death and non-fatal events have distinct cutoff points on $Z_1$

]

.right-column[
```{r, echo=FALSE, out.width='70%', fig.align='center'}
knitr::include_graphics('figures/chap5/sim1-b-500.png')
```
]

]

]

---
# Example: INVESTED trial

--

<br>

- Study sample: A subset of the INVESTED trial with 1,200 patients (HD-TIV: 582  and SD-QIV:618)

--

- Treat all non-fatal cardiopulmonary events as recurrent events

  - Focus on the **top three recurrent events**, a multistate process with $K=3$ and state $4$ represents the state of death

--

- Fit a Multistate-tree ( $\tau$=maximum event time, `maxdepth` = 4, `minsplit` = 150)

--

- Predictors: 10 risk factors  



---
.panelset[

.panel[.panel-name[ Tree ]

```{r, echo=FALSE, out.width='75%', fig.align='center'}
knitr::include_graphics('figures/chap5/realdata-tree.png')
```

]

.panel[.panel-name[ Node 1&2 ]

Plot the Kaplan-Meier curves for the transition times $T_k$

```{r, echo=FALSE, out.width='85%', fig.align='center'}
knitr::include_graphics('figures/chap5/realdata1.png')
```

]

.panel[.panel-name[ Node 6&7 ]

Plot the Kaplan-Meier curves for the transition times $T_k$

```{r, echo=FALSE, out.width='85%', fig.align='center'}
knitr::include_graphics('figures/chap5/realdata2.png')
```

]

.panel[.panel-name[ Risk prediction at month 15]

Risk prediction at time $t$

- Use $1 - S_k(t | h)$ to predict the risk for each transition times $T_k$

- **Node 8** (Renal impairment and age $\geq$ 75): in 15 months, the patients in node 8 have

  - 52.0% risk of at least 1 CV event or death
  
  - 42.2% risk of at least 2 CV events or death

```{r, echo=FALSE}

df <- data.frame(
  
  node = c("1", "2", "3", "4", "5", "6", "7", '<span style="color:#dc2f02">8</span>'),
  state1 = c("0.168","0.337","0.290", "0.286", "0.508", "0.455", "0.680", '<span style="color:#dc2f02">0.540</span>'),
  state2 = c("0.080", "0.176", "0.176", "0.034", "0.321", "0.268", "0.424", '<span style="color:#dc2f02">0.422</span>'),
  state3 = c("0.052", "0.082", "0.165", "0.034", "0.206", "0.213", "0.273", '<span style="color:#dc2f02">0.354</span>'),
  state4 = c("0.022", "0.030", "0.172", "0.022", "0.131", "0.137", "0.168", '<span style="color:#dc2f02">0.262</span>')
  
)

DT::datatable(
  df[c(1,2,6,7,8),], 
  options = list(dom = 't',pageLength = 10,
                 columnDefs = list(list(className = 'dt-center', targets = 0:4))), 
  rownames = FALSE, escape = FALSE,
  colnames = c("Node", "State 1", "State 2", "State 3", "State 4"),
  caption = "Risk prediction in Month 15")

```

]

]



---
# Additional topics

--

- Performance metric
  
  - We developed a **generalized C-index** to measure the performance of the survival tree on composite endpoints

--

- A post-pruning algorithm to prune the complete the tree

  - Cost-complexity  <span style='font-size:13pt; color:#707070'> (Breiman et al.1984)</span>  : For a tree $\mathcal{T}$ with terminal nodes $\widetilde{\mathcal{T}}$, the cost-complexity is
$$\mathcal{R}_\alpha(\mathcal{T}) = \mathcal{R}(\mathcal{T}) + \alpha |\widetilde{\mathcal{T}}|$$
  
  - $\alpha$ is a penalty parameter, $|\widetilde{\mathcal{T}}|$ is number of terminal nodes in $\mathcal{T}$

  - $\mathcal{R}(\mathcal{T}) = \sum_{h\in \widetilde{\mathcal{T}}}\mathcal{R}(h)$, and $\mathcal{R}(h)$ is within-node risk of $h$ which measures the impurity of the node

  - **Weighted Gini index** for pruning

--

- Ensemble method: combine multiple individual trees

  - bagging and random forests <span style='font-size:13pt; color:#707070'>  (Breiman, 1996; Breiman, 2001)</span>



---
class: inverse, center, middle

## .fancy[Chapter 5.] Summary 

---
# Summary

<br>

--

- non-randomized cohorts of a multi-season trial with randomize-once strategy

  - .uw-anchor-color[IPTW inference scheme]

--

- Prioritized composite endpoints

  - estimand (hypothesis testing) $\,\,\,$ `r anicon::faa("arrow-circle-right", animate="passing", size=1.2, speed="slow")` $\,\,\,$ .uw-anchor-color[restricted time win ratio]
  
  - regression $\,\,\,$ `r anicon::faa("arrow-circle-right", animate="passing", size=1.2, speed="slow")` $\,\,\,$  .uw-anchor-color[stratified proportional win-fractions models]
  
  - prediction $\,\,\,$ `r anicon::faa("arrow-circle-right", animate="passing", size=1.2, speed="slow")` $\,\,\,$  .uw-anchor-color[survival tree]


---
class: center, middle
background-image: url(https://raw.githubusercontent.com/ttuowang/BMI-881-Literature-Seminar/master/color-flush-UWlogo-print.png)
background-size: 250px
background-position: 9% 15%


`r anicon::nia("<span style='font-size:55pt; color:#cc0033'> Thanks! </span>", animate = "tada")`

<br>

`r anicon::faa("envelope-open", animate="float", color="#222831")` : twang437@wisc.edu

`r anicon::faa("twitter", animate="float", color="#00acee")` : @alextuowang

`r anicon::faa("id-card", animate="float", color="#393E46")` : tuowang.rbind.io


---
# `r anicon::nia("References", animate = "float")` 

- .uw-anchor-color[.bold[Wang, T.]] and Mao, L. (2023+). Survival trees for complex life history data. *In preparation*.

- .uw-anchor-color[.bold[Wang, T.]], Mao, L., Cocco, A., Kim, K. (2023+). Statistical inference for complex time to event data under non-randomized cohorts. *Statistics in Medicine*, *Under Revision*

- .uw-anchor-color[.bold[Wang, T.]], Qu, Y., and Li, Y. (2023+). Win ratio: from estimands to estimation. *Statistics in Medicine*, *Under Review*

- Mao, L. and .uw-anchor-color[.bold[Wang, T.]] (2023). Dissecting the restricted mean time in favor of treatment.  *Journal of Biopharmaceutical Statistics*, doi:10.1080/10543406.2023.2210658

- .uw-anchor-color[.bold[Wang, T.]] </span>, Zilinskas, R., Li, Y, Qu, Y. (2023). Missing data imputation for a multivariate outcome of mixed variable types. *Statistics in Biopharmaceutical Research*, doi: 10.1080/19466315.2023.2169753

- .uw-anchor-color[.bold[Wang, T.]] and Mao, L. (2022). Stratified proportional win-fractions regression analysis. *Statistics in Medicine*, 41, 5305-5318

- Mao, L. and .uw-anchor-color[.bold[Wang, T.]] (2021). A Class of Proportional Win-Fractions Regression Models for Composite Outcomes. *Biometrics*, 77, 1265-1275

---
# References

- Austin, P. C. (2011). An introduction to propensity score methods for reducing the effects
of confounding in observational studies. Multivariate Behavioral Research 46, 399–424.

- Austin, P. C. (2016). Variance estimation when using inverse probability of treatment
weighting (IPTW) with survival analysis. Statistics in Medicine 35, 5642–5655.

- Bou-Hamad, I., Larocque, D., and Ben-Ameur, H. (2011b). A review of survival trees.
Statistics Surveys 5, 44 – 71.

- Breiman, L. (1996). Bagging predictors. Machine Learning 24, 123–140.

- Breiman, L. (2001). Random forests. Machine Learning 45, 5–32.

- Breiman, L., Friedman, J., Olshen, R., and Stone, C. (1984). Classification and regression
trees. Wadsworth International Group 37, 237–251.

- Buyse, M. (2010). Generalized pairwise comparisons of prioritized outcomes in the two-
sample problem. Statistics in Medicine 29, 3245–3257.

- Dong, G., Hoaglin, D. C., Qiu, J., Matsouaka, R. A., Chang, Y.-W., Wang, J., and
Vandemeulebroecke, M. (2020). The win ratio: on interpretation and handling of ties.
Statistics in Biopharmaceutical Research 12, 99–106.

---
# References

- Fan, J., Su, X.-G., Levine, R. A., Nunn, M. E., and LeBlanc, M. (2006). Trees for correlated survival data by goodness of split, with applications to tooth prognosis. Journal
of the American Statistical Association 101, 959–967.

- ICH E9 (R1) (2020). Addendum on estimands and sensitivity analysis in clinical tri-
als to the guideline on statistical principles for clinical trials. Technical report,
EMA/CHMP/ICH/436221/2017, Step 5 (Final Version adopted on 17 Feb 2020)

- LeBlanc, M. and Crowley, J. (1992). Relative risk trees for censored survival data. Bio-
metrics pages 411–425.

- LeBlanc, M. and Crowley, J. (1993). Survival trees by goodness of split. Journal of the
American Statistical Association 88, 457–467

- Mao, L. (2023). On restricted mean time in favor of treatment. Biometrics, 79, 61-72.

- Pocock, S. J., Ariti, C. A., Collier, T. J., and Wang, D. (2012). The win ratio: a new
approach to the analysis of composite endpoints in clinical trials based on clinical pri-
orities. European heart journal 33, 176–182

- Rosenbaum, P. and Rubin, D. (1983). The central role of the propensity score in observa-
tional studies for causal effects. Biometrika 70, 41–55.

---
# References

- Rubin, D. (1987). Multiple Imputation for Nonresponse in Surveys. New York: John
Wiley & Sons Inc.

- Therneau, T. M., Grambsch, P. M., and Fleming, T. R. (1990). Martingale-based residuals
for survival models. Biometrika 77, 147–160.

- Vardeny, O., Kim, K., Udell, J. A., Joseph, J., Desai, A. S., Farkouh, M. E., et al. (2021).
Effect of high-dose trivalent vs standard-dose quadrivalent influenza vaccine on mortality
or cardiopulmonary hospitalization in patients with high-risk cardiovascular disease: a
randomized clinical trial. JAMA 325, 39–49.

- Xie, J. and Liu, C. (2005). Adjusted Kaplan–Meier estimator and log-rank test with
inverse probability of treatment weighting for survival data. Statistics in Medicine 24,
3089–3110.

---
class: inverse, center, middle

## .fancy[Appendix] 

---
# Generalized C-index 

Performance metric measure the predictive power of a model

  - classification: accuracy
  
  - regression: mean squared error
  
  - survival data: C-index and Brier score

Then **C-index** is defined as 
$$\mathcal{C} = \text{pr}\left\{ g(\boldsymbol{Z_i}) > g(\boldsymbol{Z_j}) \mid D_i < D_j \right\}$$

- $g(\cdot)$ is a risk prediction function, e.g., the Cox model, with larger values indicating higher risks of death

- $\boldsymbol{Z} = (Z_1, \ldots, Z_p)^\mathrm{T}$, a $p$-dimensional vector of baseline covariates

`r anicon::faa("exclamation", animate="pulse", size=1.2)` Need to develop a metric to measure the performance of the survival tree on composite endpoints.

???
The C-index is a measure of the probability that the predicted risks of two randomly selected individuals have the same relative order as their true event times

---
# Generalized C-index <span style='font-size:18pt; color:black'> `r icons::fontawesome("arrow-circle-right")` </span> <span style='font-size:23pt; color:black'> Formulation </span>

Given a grown tree $\mathcal{T}$, let $h_{\boldsymbol{z}}$ denote the terminal node in which covariate $\boldsymbol{z}$ falls. The within-node class probabilities are defined by
$$\boldsymbol{\mathcal{P}}_{\mathcal{T}}(t \mid \boldsymbol{z})=\Bigl[ \operatorname{pr}\left\{Y(t)=1 \mid h_{\boldsymbol{z}}\right\}, \ldots, \operatorname{pr}\left\{Y(t)=K \mid h_{\boldsymbol{z}}\right\}, \operatorname{pr}\left\{Y(t)=K+1 \mid h_{\boldsymbol{z}}\right\} \Bigr]^{\mathrm{T}}$$

Consider an ordinal random variable $\widehat{Y}(t | \boldsymbol{z};\mathcal{P}_\mathcal{T}) \in \{0, \ldots, K+1\}$ with class probabilities 
- $\text{pr}\{\widehat{Y}(t | \boldsymbol{z};\mathcal{P}_\mathcal{T}) = k\} = \operatorname{pr}\left\{Y(t)=k \mid h_{\boldsymbol{z}}\right\}$ for $k=1, \ldots, K+1$ 

- $\text{pr}\{\widehat{Y}(t | \boldsymbol{z};\mathcal{P}_\mathcal{T}) = 0\} = 1- \sum_{k=1}^{K+1} \operatorname{pr}\left\{Y(t)=k \mid h_{\boldsymbol{z}}\right\}$ 

This leads us to define the **generalized C-index**
$$\mathcal{C}(\mathcal{T})(t)=E\left[\mathcal{L}\left\{\boldsymbol{P}_{\mathcal{T}}\left(t \mid \boldsymbol{Z}_{i}\right), \boldsymbol{P}_{\mathcal{T}}\left(t \mid \boldsymbol{Z}_{j}\right)\right\} \mid Y_{i}(t)<Y_{j}(t)\right],$$
where $\small \mathcal{L}\left\{\boldsymbol{P}_{\mathcal{T}}\left(t \mid \boldsymbol{Z}_{i}\right), \boldsymbol{P}_{\mathcal{T}}\left(t \mid \boldsymbol{Z}_{j}\right)\right\} = \operatorname{pr} \left\{ \widehat{Y}_i(t | \boldsymbol{Z}_i;\mathcal{P}_\mathcal{T})  < \widehat{Y}_j(t | \boldsymbol{Z}_j;\mathcal{P}_\mathcal{T}) \right\} + 2^{-1} \operatorname{pr} \left\{ \widehat{Y}_i(t | \boldsymbol{Z}_i;\mathcal{P}_\mathcal{T})  = \widehat{Y}_j(t | \boldsymbol{Z}_j;\mathcal{P}_\mathcal{T}) \right\}$.

---
# Generalized C-index <span style='font-size:18pt; color:black'> `r icons::fontawesome("arrow-circle-right")` </span> <span style='font-size:23pt; color:black'> Formulation </span>


- After algebraic manipulation, we have
$$\begin{aligned}\mathcal{L}\left\{\boldsymbol{P}_{\mathcal{T}}\left(t \mid \boldsymbol{Z}_{i}\right), \boldsymbol{P}_{\mathcal{T}}\left(t \mid \boldsymbol{Z}_{j}\right)\right\} &=  \sum_{l=1}^{K+1} \sum_{k=0}^{l-1} \operatorname{pr}\left\{Y_{i}(t)=k \mid h_{\boldsymbol{Z}_{i}}\right\} \operatorname{pr}\left\{Y_{j}(t)=l \mid h_{\boldsymbol{Z}_{j}}\right\} \\ 
& \,\,\,\,\,\, +2^{-1}\sum_{k=0}^{K+1}\operatorname{pr}\left\{Y_{i}(t)=k \mid h_{\boldsymbol{Z}_{i}}\right\}\operatorname{pr}\left\{Y_{j}(t)=k \mid h_{\boldsymbol{Z}_{j}}\right\}.\end{aligned}$$


- $\mathcal{L}\left\{\boldsymbol{P}_{\mathcal{T}}\left(t \mid \boldsymbol{Z}_{i}\right), \boldsymbol{P}_{\mathcal{T}}\left(t \mid \boldsymbol{Z}_{j}\right)\right\}$ is the probability that subject $i$ occupy an earlier state than subject $j$


- Then the overall concordance is defined by
$\mathcal{C}(\mathcal{T}) = \frac{1}{\tau}\int_{0}^{\tau}\mathcal{C}(\mathcal{T})(t) \mathrm{d}t$
  - $\mathcal{C}(\mathcal{T}) \in [0, 1]$ and $\mathcal{C}(\mathcal{T}) = 0.5$ indicates random guess


  - In the presence of censoring, $\mathcal{C}(\mathcal{T})$ can be estimated via inverse probability censoring weighting (IPCW)

---
# Generalized C-index  <span style='font-size:18pt; color:black'> `r icons::fontawesome("arrow-circle-right")` </span> <span style='font-size:23pt; color:black'> Estimation </span>

**Proposition**: Under (A1) and (A2), $C(\mathcal{T})(t)$ can be consistently estimated by
$$\widehat{\mathcal{C}}(\mathcal{T})(t) = \frac{\sum_{i=1}^{n}\sum_{j=1}^{n} \mathcal{L}\left\{\widehat{\boldsymbol{P}}_{\mathcal{T}}\left(t \mid \boldsymbol{Z}_{i}\right), \widehat{\boldsymbol{P}}_{\mathcal{T}}\left(t \mid \boldsymbol{Z}_{j}\right)\right\} \widehat{w}_{ij}(t) }{ \sum_{i=1}^{n}\sum_{j=1}^{n} \widehat{w}_{ij}(t) },$$
where 
$$\begin{aligned} \widehat{w}_{ij}(t) &= \sum_{k=1}^{K} \left\{ I\left(X_i^{(k)} > t\right) I\left(X_j^{(k)} \leq t < X_j^{(k+1)}\right)  \delta_j^{(k)}\widehat{G}(t)^{-2}\right\} \\
& \,\,\,\,\,\,+   I\left(X_i^{(K+1)} > t\right) I\left(X_j^{(K+1)} \leq t \right)  \delta_j^{(K+1)}\widehat{G}\left(T_j^{(K+1)}\right)^{-1}\widehat{G}(t)^{-1} \end{aligned}$$

$\widehat{G}(t)$ is the Kaplan–Meier estimator for the censoring distribution $G(t) = \operatorname{pr}(C > t)$  and $\widehat{\boldsymbol{P}}_{\mathcal{T}}\left(t \mid \boldsymbol{Z}_{i}\right)$ is the Kaplan-Meier estimator for $\boldsymbol{P}_{\mathcal{T}}\left(t \mid \boldsymbol{Z}_{i}\right)$.

---
# Simulation <span style='font-size:18pt; color:black'> `r icons::fontawesome("arrow-circle-right")` </span> <span style='font-size:23pt; color:black'> Model performance </span>


.panelset[

.panel[.panel-name[ Set-up ]

- $Z_1 \sim \text{Uniform}[0,2]$, $Z_2 \sim \text{Bernoulli}(0.5)$, $Z_3 \sim \text{Bernoulli}(0.5)$, and $Z_4 \sim \text{Bernoulli}(0.5)$

- trivariate Gumbel-Hougaard copula model: $$\operatorname{pr}\left\{ \widehat{T}_1 > t_1, \widehat{T}_2>t_2, D>s | {Z}_1, {Z}_2, {Z}_3 \right\} = \exp\left[ -\left\{ (\lambda_{1}  t_1)^{\kappa}+ (\lambda_{2} t_2)^{\kappa} + (\lambda_{3} s)^{\kappa} \right\}^{1/{\kappa}}  \right]$$

  - $\lambda_{a} = 0.1 + \mu_{a} I(Z_1 > \phi_a) + \theta_{a} Z_2 I(Z_1 > \phi_a) + 0.5\theta_{a} Z_3 I(Z_1 \leq \phi_a)$ for $a=1,2,3$
  
- Scenario 1: $\phi_a = 0.8$ for $a=1,2,3$, where the true structure of the data is known

- Scenario 2: $\phi_1=\phi_2=0.5$ and $\phi_3=1.5$

]

.panel[.panel-name[ Results ]

.left-column[

- sample size $n=500$

- training data: $n=400$

- testing data: $n=100$

- Mean generalized C-index over 1,000 replicates

- Note that the generalized C-index tends to underestimate the true prediction power

]

.right-column[
```{r, echo=FALSE}

df <- data.frame(
  
  a = c("1", "", "2", ""),
  mu = c("(0.6, 0.6, 0.6)", "0.8, 0.8, 0.8", "0.6, 0.6, 0.6", "0.8, 0.8, 0.8"),
  theta = c("0.5, 0.5, 0.5", "0.7, 0.7, 0.7", "0.5, 0.5, 0.5", "0.7, 0.7, 0.7"),
  mul = c("0.631", "0.661", "0.572", "0.592"),
  tfe = c("0.627", "0.658", "0.561", "0.575"),
  truee = c("0.632", "0.662", "-", "-"),
  random=c("0.498", "0.499", "0.499", "0.499")
  
)

DT::datatable(
  df, 
  options = list(dom = 't',pageLength = 10,
                 columnDefs = list(list(className = 'dt-center', targets = 0:6))), 
  rownames = FALSE, escape = FALSE,
  colnames = c("Scenario", "mu", "theta", "Multistate", "TFE", "True", "Random"))
```

]
]
]

